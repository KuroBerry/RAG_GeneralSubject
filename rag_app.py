import streamlit as st

# Page config must be first Streamlit command
st.set_page_config(
    page_title="RAG Political Science Chatbot",
    page_icon="ğŸ“",
    layout="centered"
)

import sys
import os
import time
from datetime import datetime

# Add current directory to path
sys.path.append(os.path.dirname(__file__))

# Demo functions first (in case real imports fail)
def demo_parent_document_search(query, **kwargs):
    """Demo version of parent_document_search"""
    time.sleep(1)  # Simulate processing
    
    demo_responses = {
        "Ä‘áº£ng cá»™ng sáº£n": "Äáº£ng Cá»™ng sáº£n Viá»‡t Nam Ä‘Æ°á»£c thÃ nh láº­p ngÃ y 3/2/1930 táº¡i Há»“ng KÃ´ng do Chá»§ tá»‹ch Há»“ ChÃ­ Minh sÃ¡ng láº­p.",
        "tÆ° tÆ°á»Ÿng há»“ chÃ­ minh": "TÆ° tÆ°á»Ÿng Há»“ ChÃ­ Minh lÃ  há»‡ thá»‘ng quan Ä‘iá»ƒm toÃ n diá»‡n vá» cÃ¡ch máº¡ng Viá»‡t Nam, bao gá»“m Ä‘á»™c láº­p dÃ¢n tá»™c vÃ  chá»§ nghÄ©a xÃ£ há»™i.",
        "triáº¿t há»c": "Triáº¿t há»c Marxism-Leninism lÃ  ná»n táº£ng tÆ° tÆ°á»Ÿng cá»§a Äáº£ng, giÃºp nháº­n thá»©c Ä‘Ãºng Ä‘áº¯n vá» tháº¿ giá»›i vÃ  xÃ£ há»™i."
    }
    
    query_lower = query.lower()
    content = "Demo content cho cÃ¢u há»i: " + query
    for keyword, response in demo_responses.items():
        if keyword in query_lower:
            content = response
            break
    
    return [{
        'parent_chunk': {'metadata': {'content': content, 'chapter': 'Demo Chapter', 'section': 'Demo Section'}},
        'parent_id': f'demo_{abs(hash(query)) % 1000:03d}',
        'score': 0.95,
        'child_count': 3
    }]

def demo_generate_answer(query, context):
    """Demo version of generate_answer"""
    time.sleep(1)  # Simulate processing
    
    context_text = ""
    for metadata, parent_id in context:
        content = metadata.get('content', '')
        context_text += f"ğŸ“– {content[:150]}... (ID: {parent_id})\n\n"
    
    return f"""**CÃ¢u há»i:** {query}

**ThÃ´ng tin tÃ¬m Ä‘Æ°á»£c:**
{context_text}

**Tráº£ lá»i:** Dá»±a trÃªn tÃ i liá»‡u tÃ¬m Ä‘Æ°á»£c, Ä‘Ã¢y lÃ  cÃ¢u tráº£ lá»i demo cho cÃ¢u há»i cá»§a báº¡n.

âš ï¸ **Demo Mode**: Äá»ƒ cÃ³ cÃ¢u tráº£ lá»i chÃ­nh xÃ¡c, vui lÃ²ng cáº¥u hÃ¬nh API keys trong file .env

*Nguá»“n: RAG Demo System*"""

# Try to import real functions
RETRIEVAL_AVAILABLE = False
retrieval_status = "âš ï¸ Initializing..."

# Defer imports that might contain Streamlit decorators
parent_document_search = None
generate_answer = None
initialize_connections = None

try:
    # Load environment variables first
    from dotenv import load_dotenv
    import os
    
    # Try multiple paths for .env
    env_loaded = False
    for env_path in ['.env', '../.env', './.env']:
        try:
            load_dotenv(env_path)
            if os.getenv('PINECONE_API_KEY') and os.getenv('HOST_DENSE') and os.getenv('GEMINI_API_KEY'):
                env_loaded = True
                break
        except:
            continue
    
    if not env_loaded:
        raise Exception("Environment variables not found")
    
    # Import retrieval functions AFTER page config
    from retriever.parent_retrieval import parent_document_search, generate_answer, initialize_connections
    
    # Try to initialize
    initialize_connections()
    RETRIEVAL_AVAILABLE = True
    retrieval_status = "âœ… RAG system active with real APIs"
    
except Exception as e:
    retrieval_status = f"âš ï¸ Demo mode: {str(e)[:60]}..."

# CSS
st.markdown("""
<style>
    .chat-message {
        padding: 1rem;
        border-radius: 15px;
        margin: 1rem 0;
        box-shadow: 0 2px 5px rgba(0,0,0,0.1);
    }
    .user-message {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        margin-left: 10%;
    }
    .bot-message {
        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        color: white;
        margin-right: 10%;
    }
    .source-card {
        background: #f8f9fa;
        border-left: 4px solid #007bff;
        padding: 0.8rem;
        margin: 0.5rem 0;
        border-radius: 0 8px 8px 0;
        font-size: 0.9rem;
        color: #333333;
        box-shadow: 0 1px 3px rgba(0,0,0,0.1);
    }
    .source-card strong {
        color: #007bff;
        font-weight: 600;
    }
    
    /* Improve readability for expandable sections */
    .streamlit-expanderHeader {
        background-color: #f8f9fa !important;
        border-radius: 5px !important;
    }
    
    /* Custom styling for metrics */
    .metric-container {
        background: linear-gradient(135deg, #e3f2fd 0%, #f3e5f5 100%);
        padding: 0.5rem;
        border-radius: 8px;
        margin: 0.2rem 0;
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state
if "messages" not in st.session_state:
    st.session_state.messages = []
if "total_queries" not in st.session_state:
    st.session_state.total_queries = 0

# Header
st.title("ğŸ“ RAG Political Science Chatbot")

# Debug info
with st.expander("ğŸ”§ System Debug Info", expanded=False):
    st.code(f"Status: {retrieval_status}")
    
    # Check .env file
    import os
    env_file_exists = os.path.exists('.env')
    st.write(f"ğŸ“ .env file exists: {'âœ…' if env_file_exists else 'âŒ'}")
    
    if env_file_exists:
        from dotenv import load_dotenv
        load_dotenv()
        st.write(f"ğŸ”‘ PINECONE_API_KEY: {'âœ… Found' if os.getenv('PINECONE_API_KEY') else 'âŒ Missing'}")
        st.write(f"ğŸŒ HOST_DENSE: {'âœ… Found' if os.getenv('HOST_DENSE') else 'âŒ Missing'}")
        st.write(f"ğŸ¤– GEMINI_API_KEY: {'âœ… Found' if os.getenv('GEMINI_API_KEY') else 'âŒ Missing'}")
    
    # Cache status
    st.subheader("ğŸš€ Cache Status")
    try:
        # Try to get cache stats if available
        cache_info = getattr(st.cache_data, 'get_stats', lambda: {})()
        st.write(f"ğŸ“Š Cache entries: {len(cache_info) if cache_info else 'N/A'}")
    except:
        st.write("ğŸ“Š Cache monitoring: Available")
    
    if RETRIEVAL_AVAILABLE:
        st.write("âœ… Embedding model: Cached")
        st.write("âœ… Pinecone connection: Cached") 
        st.write("âœ… Gemini client: Cached")
    else:
        st.write("âš ï¸ Cache status: Demo mode")

st.markdown(f"**Status:** {retrieval_status}")

# Mode indicator
if RETRIEVAL_AVAILABLE:
    st.success("ğŸš€ **Full RAG Mode**: Parent Document Retrieval Active")
else:
    st.warning("ğŸ”§ **Demo Mode**: Showing sample responses")

st.markdown("---")

# Sidebar
with st.sidebar:
    st.header("ğŸ”§ Settings")
    
    # RAG parameters
    top_k = st.slider("Results", 1, 10, 5)
    alpha = st.slider("Score weight", 0.0, 1.0, 0.7, 0.1)
    
    # Namespaces
    st.subheader("ğŸ“š Data Source")
    child_ns = st.selectbox("Child namespace", 
                           ["lich-su-dang-children", "triet-hoc-children", "tu-tuong-hcm-children"])
    parent_ns = st.selectbox("Parent namespace", 
                            ["lich-su-dang", "triet-hoc", "tu-tuong-hcm"])
    
    # Stats
    st.subheader("ğŸ“Š Statistics")
    st.metric("Total Queries", st.session_state.total_queries)
    
    if st.session_state.messages:
        # Calculate average response time
        response_times = []
        for msg in st.session_state.messages:
            if msg["role"] == "assistant" and "response_time" in msg:
                try:
                    rt = float(msg["response_time"])
                    response_times.append(rt)
                except:
                    pass
        
        if response_times:
            avg_time = sum(response_times) / len(response_times)
            st.metric("Avg Response Time", f"{avg_time:.2f}s")
            st.metric("Last Response", f"{response_times[-1]:.2f}s")
    
    # Cache efficiency
    if RETRIEVAL_AVAILABLE:
        st.success("ğŸš€ Using cached resources")
    else:
        st.info("ğŸ”§ Demo mode active")
    
    # Clear button
    if st.button("ğŸ—‘ï¸ Clear Chat", use_container_width=True):
        st.session_state.messages = []
        st.session_state.total_queries = 0
        st.rerun()
    
    # Clear cache button (for debugging)
    if st.button("ğŸ§¹ Clear Cache", use_container_width=True):
        st.cache_data.clear()
        st.cache_resource.clear()
        st.success("Cache cleared!")
        st.rerun()

# Display messages
for message in st.session_state.messages:
    if message["role"] == "user":
        st.markdown(f"""
        <div class="chat-message user-message">
            <strong>ğŸ§‘â€ğŸ“ You:</strong><br>{message["content"]}
            <small style="opacity:0.8;display:block;margin-top:0.5rem;">
                {message.get("timestamp", "")}
            </small>
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown(f"""
        <div class="chat-message bot-message">
            <strong>ğŸ¤– Assistant:</strong><br>{message["content"]}
            <small style="opacity:0.8;display:block;margin-top:0.5rem;">
                â±ï¸ {message.get("response_time", "N/A")}s | ğŸ“š {message.get("source_count", 0)} sources
            </small>
        </div>
        """, unsafe_allow_html=True)
        
        # Sources
        if "sources" in message and message["sources"]:
            with st.expander(f"ğŸ“š {len(message['sources'])} Sources"):
                for i, src in enumerate(message["sources"], 1):
                    st.markdown(f"""
                    <div class="source-card">
                        <div style="margin-bottom: 0.5rem;">
                            <strong>Source {i}</strong> | 
                            <span style="color: #28a745;">Score: {src['score']:.4f}</span> | 
                            <span style="color: #6c757d;">Children: {src['child_count']}</span>
                        </div>
                        <div style="margin-bottom: 0.3rem;">
                            <strong>ID:</strong> <code style="background: #e9ecef; padding: 2px 4px; border-radius: 3px; color: #495057;">{src['parent_id']}</code>
                        </div>
                        <div>
                            <strong>Content:</strong><br>
                            <span style="color: #495057; line-height: 1.4;">{src['content'][:300]}...</span>
                        </div>
                    </div>
                    """, unsafe_allow_html=True)

# Input
st.markdown("### ğŸ’¬ Ask a Question")
user_input = st.text_input("", placeholder="e.g., Äáº£ng Cá»™ng sáº£n Viá»‡t Nam Ä‘Æ°á»£c thÃ nh láº­p khi nÃ o?")

col1, col2 = st.columns([3, 1])
with col1:
    send_btn = st.button("ğŸš€ Send", use_container_width=True, type="primary")
with col2:
    help_btn = st.button("ğŸ’¡ Examples", use_container_width=True)

# Example questions
if help_btn:
    examples = [
        "Äáº£ng Cá»™ng sáº£n Viá»‡t Nam Ä‘Æ°á»£c thÃ nh láº­p khi nÃ o?",
        "TÆ° tÆ°á»Ÿng Há»“ ChÃ­ Minh lÃ  gÃ¬?",
        "Triáº¿t há»c Marxism-Leninism cÃ³ Ä‘áº·c Ä‘iá»ƒm gÃ¬?",
        "Vai trÃ² cá»§a Äáº£ng trong cÃ¡ch máº¡ng Viá»‡t Nam?"
    ]
    
    st.markdown("**ğŸ“ Example Questions:**")
    for ex in examples:
        if st.button(f"â€¢ {ex}", key=f"ex_{abs(hash(ex))%1000}"):
            # Add to messages
            st.session_state.messages.append({
                "role": "user", 
                "content": ex,
                "timestamp": datetime.now().strftime("%H:%M:%S")
            })
            # Process immediately
            with st.spinner("ğŸ” Processing..."):
                start_time = time.time()
                
                if RETRIEVAL_AVAILABLE:
                    results = parent_document_search(ex, child_ns, parent_ns, top_k, alpha)
                else:
                    results = demo_parent_document_search(ex)
                
                if results:
                    context = [(r['parent_chunk']['metadata'], r['parent_id']) for r in results]
                    if RETRIEVAL_AVAILABLE:
                        answer = generate_answer(ex, context)
                    else:
                        answer = demo_generate_answer(ex, context)
                    
                    response_time = time.time() - start_time
                    st.session_state.total_queries += 1
                    
                    sources = [{
                        'parent_id': r['parent_id'],
                        'score': r['score'],
                        'child_count': r['child_count'],
                        'content': r['parent_chunk']['metadata'].get('content', 'No content')
                    } for r in results]
                    
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": answer,
                        "response_time": f"{response_time:.2f}",
                        "source_count": len(results),
                        "sources": sources
                    })
            st.rerun()

# Process input
if send_btn and user_input.strip():
    # Add user message
    timestamp = datetime.now().strftime("%H:%M:%S")
    st.session_state.messages.append({
        "role": "user", 
        "content": user_input,
        "timestamp": timestamp
    })
    
    # Process
    with st.spinner("ğŸ” Searching documents..."):
        start_time = time.time()
        
        try:
            # Search
            if RETRIEVAL_AVAILABLE:
                results = parent_document_search(user_input, child_ns, parent_ns, top_k, alpha)
            else:
                results = demo_parent_document_search(user_input)
            
            if results:
                # Generate answer
                context = [(r['parent_chunk']['metadata'], r['parent_id']) for r in results]
                
                if RETRIEVAL_AVAILABLE:
                    answer = generate_answer(user_input, context)
                else:
                    answer = demo_generate_answer(user_input, context)
                
                response_time = time.time() - start_time
                st.session_state.total_queries += 1
                
                # Prepare sources
                sources = [{
                    'parent_id': r['parent_id'],
                    'score': r['score'],
                    'child_count': r['child_count'],
                    'content': r['parent_chunk']['metadata'].get('content', 'No content')
                } for r in results]
                
                # Add response
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": answer,
                    "response_time": f"{response_time:.2f}",
                    "source_count": len(results),
                    "sources": sources
                })
            else:
                # No results
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": "Xin lá»—i, khÃ´ng tÃ¬m tháº¥y thÃ´ng tin liÃªn quan. Vui lÃ²ng thá»­ cÃ¢u há»i khÃ¡c.",
                    "response_time": "N/A",
                    "source_count": 0,
                    "sources": []
                })
                
        except Exception as e:
            st.session_state.messages.append({
                "role": "assistant",
                "content": f"Lá»—i xá»­ lÃ½: {str(e)}",
                "response_time": "N/A",
                "source_count": 0,
                "sources": []
            })
    
    st.rerun()

# Footer
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666;">
    <small>ğŸ“ RAG Political Science Assistant | Parent Document Retrieval</small>
</div>
""", unsafe_allow_html=True)
