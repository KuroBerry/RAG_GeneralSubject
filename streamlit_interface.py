import time
import random
import threading
import streamlit as st
from agent import get_router
from langchain_community.chat_message_histories import StreamlitChatMessageHistory
from retriever.parent_retrieval import parent_document_search as parent_retrieval
from agent import generate_answer

# Cache responses cho normal chatting
NORMAL_RESPONSES = [
    "Xin ch√†o! T√¥i l√† tr·ª£ l√Ω AI c·ªßa b·∫°n. T√¥i c√≥ th·ªÉ gi√∫p b·∫°n tr·∫£ l·ªùi c√°c c√¢u h·ªèi v·ªÅ Tri·∫øt h·ªçc M√°c-L√™nin v√† L·ªãch s·ª≠ ƒê·∫£ng. B·∫°n c√≥ c√¢u h·ªèi g√¨ kh√¥ng?",
    "Ch√†o b·∫°n! R·∫•t vui ƒë∆∞·ª£c tr√≤ chuy·ªán v·ªõi b·∫°n. T√¥i c√≥ th·ªÉ h·ªó tr·ª£ b·∫°n v·ªÅ c√°c v·∫•n ƒë·ªÅ h·ªçc thu·∫≠t li√™n quan ƒë·∫øn Tri·∫øt h·ªçc v√† L·ªãch s·ª≠ ƒê·∫£ng.",
    "Hi! T√¥i ·ªü ƒë√¢y ƒë·ªÉ gi√∫p b·∫°n. H√£y ƒë·∫∑t c√¢u h·ªèi v·ªÅ Tri·∫øt h·ªçc M√°c-L√™nin ho·∫∑c L·ªãch s·ª≠ ƒê·∫£ng nh√©!",
    "Ch√†o b·∫°n! T√¥i lu√¥n s·∫µn s√†ng h·ªó tr·ª£ b·∫°n. C√≥ ƒëi·ªÅu g√¨ t√¥i c√≥ th·ªÉ gi√∫p v·ªÅ Tri·∫øt h·ªçc v√† L·ªãch s·ª≠ ƒê·∫£ng kh√¥ng?",
    "Xin ch√†o! T√¥i l√† tr·ª£ l√Ω chuy√™n v·ªÅ Tri·∫øt h·ªçc v√† L·ªãch s·ª≠ ƒê·∫£ng. B·∫°n c·∫ßn t√¥i gi√∫p g√¨ h√¥m nay?",
]

UNKNOWN_RESPONSES = [
    "ƒê√¢y c√≥ v·∫ª kh√¥ng ph·∫£i l√† c√¢u h·ªèi thu·ªôc ph·∫°m vi ki·∫øn th·ª©c c·ªßa t√¥i. H√£y nh·∫≠p c√¢u h·ªèi kh√°c ƒë·ªÉ t√¥i gi√∫p b·∫°n nh√©!",
    "Xin l·ªói, t√¥i kh√¥ng c√≥ ki·∫øn th·ª©c v·ªÅ n·ªôi dung b·∫°n mu·ªën t√¨m. H√£y nh·∫≠p c√¢u h·ªèi kh√°c ƒë·ªÉ t√¥i gi√∫p b·∫°n nh√©!",
    "Ki·∫øn th·ª©c n√†y kh√¥ng n·∫±m trong ph·∫°m vi c·ªßa t√¥i. H√£y nh·∫≠p c√¢u h·ªèi kh√°c ƒë·ªÉ t√¥i gi√∫p b·∫°n nh√©!",
]

UNLOGIC_RESPONSES = [
    "C√¢u h·ªèi c·ªßa b·∫°n c√≥ v·∫•n ƒë·ªÅ v·ªÅ ng·ªØ nghƒ©a. H√£y nh·∫≠p c√¢u h·ªèi kh√°c ƒë·ªÉ t√¥i gi√∫p b·∫°n nh√©!",
    "Xin l·ªói, c√≥ v·∫ª nh∆∞ c√¢u h·ªèi c·ªßa b·∫°n ƒëang c√≥ v·∫•n ƒë·ªÅ. H√£y nh·∫≠p c√¢u h·ªèi kh√°c ƒë·ªÉ t√¥i gi√∫p b·∫°n nh√©!",
    "C√¢u n√†y kh√¥ng c√≥ ng·ªØ nghƒ©a. H√£y nh·∫≠p c√¢u h·ªèi kh√°c ƒë·ªÉ t√¥i gi√∫p b·∫°n nh√©!",
]

def reset_conversation():
    """
    ƒê·∫∑t l·∫°i to√†n b·ªô tr·∫°ng th√°i c·ªßa cu·ªôc tr√≤ chuy·ªán.
    """
    st.session_state['messages'] = [
        {"role": "assistant", "content": random.choice(
            [
                "Xin ch√†o! T√¥i l√† tr·ª£ l√Ω m√¥n c·ªßa b·∫°n. T√¥i s·∫Ω gi√∫p b·∫°n tr·∫£ l·ªùi c√°c c√¢u h·ªèi v·ªÅ Tri·∫øt h·ªçc v√† L·ªãch s·ª≠ ƒê·∫£ng. H√£y nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n v√†o √¥ b√™n d∆∞·ªõi ƒë·ªÉ b·∫Øt ƒë·∫ßu tr√≤ chuy·ªán v·ªõi t√¥i.",
                "Ch√†o b·∫°n! B·∫°n c·∫ßn t√¥i gi√∫p g√¨ kh√¥ng? T√¥i c√≥ th·ªÉ tr·∫£ l·ªùi m·ªçi c√¢u h·ªèi c·ªßa b·∫°n v·ªÅ Tri·∫øt h·ªçc v√† L·ªãch s·ª≠ ƒê·∫£ng.",
                "B·∫°n mu·ªën bi·∫øt g√¨ v·ªÅ Tri·∫øt h·ªçc v√† L·ªãch s·ª≠ ƒê·∫£ng? H√£y nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n v√†o √¥ b√™n d∆∞·ªõi ƒë·ªÉ b·∫Øt ƒë·∫ßu tr√≤ chuy·ªán v·ªõi t√¥i.",
        ])}
    ] 
    msgs = StreamlitChatMessageHistory(key="langchain_messages")
    msgs.clear()  
    st.rerun()

def response_generator(response):
    for word in response.split():
        yield word + " "
        time.sleep(0.05)

def clean_response(response):
    """
    L√†m s·∫°ch response ƒë·ªÉ hi·ªÉn th·ªã t·ªët h∆°n
    """
    if not isinstance(response, str):
        response = str(response)
    
    # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a
    response = response.strip()
    
    # Thay th·∫ø escape characters
    response = response.replace('\\n', '\n')
    response = response.replace('\\t', '\t')
    
    return response
    
def setup_page():
    """
    C·∫•u h√¨nh trang web c∆° b·∫£n
    """
    st.set_page_config(
        page_title="Legal Assistant", 
        page_icon="üí¨",
        layout="wide" 
    )

def setup_sidebar():
    with st.sidebar:
        st.markdown("""
        <h1 style='text-align: center; color: #4CAF50;'>‚öôÔ∏è C·∫•u H√¨nh</h1>
        """, unsafe_allow_html=True)
        
        with st.expander("üöÄ Ch·ªçn Model AI", expanded=True):
            model_choice = st.selectbox(
                "Ch·ªçn Model ƒë·ªÉ tr·∫£ l·ªùi:",
                ["gemini-2.5-pro", "gemini-2.5-flash"],
                index=0
            )
            st.caption("üîπ Model AI s·∫Ω ·∫£nh h∆∞·ªüng ƒë·∫øn t·ªëc ƒë·ªô v√† ƒë·ªô ch√≠nh x√°c c·ªßa c√¢u tr·∫£ l·ªùi.")
          
        with st.expander("üîé T√≠nh NƒÉng Tr√≠ch Xu·∫•t VƒÉn B·∫£n"):
            retrieval_choice = st.selectbox(
                "Ch·ªçn ph∆∞∆°ng th·ª©c truy v·∫•n:",
                ["Hybrid retrieval", "Parent documents retrieval"],
                index=0
            )
            st.caption("T√≠nh nƒÉng n√†y s·∫Ω quy·∫øt ƒë·ªãnh c√°ch d·ªØ li·ªáu ƒë∆∞·ª£c truy xu·∫•t.")
            
            num_retrieval_docs = st.slider(
                "üî¢ S·ªë l∆∞·ª£ng vƒÉn b·∫£n truy xu·∫•t:",
                min_value=1,  
                max_value=10,  
                value=5 
            )
  
            
        with st.expander("üõ† Tu·ª≥ Ch·ªçn Kh√°c"):
            if st.button("üóë X√≥a cu·ªôc tr√≤ chuy·ªán", use_container_width=True):
                reset_conversation()
            st.markdown("""
            <small style='color: grey;'>X√≥a l·ªãch s·ª≠ chat ƒë·ªÉ b·∫Øt ƒë·∫ßu cu·ªôc tr√≤ chuy·ªán m·ªõi.</small>
            """, unsafe_allow_html=True)
        
    return model_choice, retrieval_choice, num_retrieval_docs
        
def setup_chat_interface(model_choice):
    st.title("Tr·ª£ L√Ω H·ªçc Thu·∫≠t üí¨")
    if model_choice == "gemini-2.5-pro" or model_choice == "gemini-2.5-flash":
        st.caption("Tr·ª£ l√Ω AI ƒë∆∞·ª£c h·ªó tr·ª£ b·ªüi Google")

    msgs = StreamlitChatMessageHistory(key="langchain_messages")
    if "messages" not in st.session_state:
        st.session_state['messages'] = [
            {"role": "assistant", "content": random.choice(
                [
                "Xin ch√†o! T√¥i l√† tr·ª£ l√Ω m√¥n c·ªßa b·∫°n. T√¥i s·∫Ω gi√∫p b·∫°n tr·∫£ l·ªùi c√°c c√¢u h·ªèi v·ªÅ Tri·∫øt h·ªçc v√† L·ªãch s·ª≠ ƒê·∫£ng. H√£y nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n v√†o √¥ b√™n d∆∞·ªõi ƒë·ªÉ b·∫Øt ƒë·∫ßu tr√≤ chuy·ªán v·ªõi t√¥i.",
                "Ch√†o b·∫°n! B·∫°n c·∫ßn t√¥i gi√∫p g√¨ kh√¥ng? T√¥i c√≥ th·ªÉ tr·∫£ l·ªùi m·ªçi c√¢u h·ªèi c·ªßa b·∫°n v·ªÅ Tri·∫øt h·ªçc v√† L·ªãch s·ª≠ ƒê·∫£ng.",
                "B·∫°n mu·ªën bi·∫øt g√¨ v·ªÅ Tri·∫øt h·ªçc v√† L·ªãch s·ª≠ ƒê·∫£ng? H√£y nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n v√†o √¥ b√™n d∆∞·ªõi ƒë·ªÉ b·∫Øt ƒë·∫ßu tr√≤ chuy·ªán v·ªõi t√¥i.",
            ])}
        ]
        msgs.add_ai_message(st.session_state.messages[0]["content"])
    
    for msg in st.session_state['messages']:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])
    return msgs

def user_input(msgs, model_choice, retrieval_choice):
    if input_query:= st.chat_input("H√£y h·ªèi t√¥i b·∫•t c·ª© ƒëi·ªÅu g√¨ v·ªÅ Tri·∫øt h·ªçc v√† L·ªãch S·ª≠ ƒê·∫£ng!"):
        st.session_state['messages'].append({"role": "user", "content": input_query})
        with st.chat_message("user"):
            st.markdown(input_query)   
        msgs.add_user_message(input_query)
        
        # Hi·ªÉn th·ªã ngay l·∫≠p t·ª©c r·∫±ng AI ƒëang x·ª≠ l√Ω
        with st.chat_message("assistant"):
            # Hi·ªÉn th·ªã spinner ngay l·∫≠p t·ª©c
            with st.spinner("ƒêang suy nghƒ©..."):
                response_placeholder = st.empty()
                timer_placeholder = st.empty()
                start_time = time.time()
                
                # Hi·ªÉn th·ªã th√¥ng b√°o ngay l·∫≠p t·ª©c
                response_placeholder.markdown("ü§î ƒêang ph√¢n t√≠ch c√¢u h·ªèi...")
                
                # Kh·ªüi t·∫°o timer ngay sau khi b·∫Øt ƒë·∫ßu
                def update_timer():
                    while True:
                        elapsed_time = time.time() - start_time
                        timer_placeholder.caption(f"‚è±Ô∏è ƒêang x·ª≠ l√Ω: {elapsed_time:.2f} gi√¢y")
                        time.sleep(0.1)

                timer_thread = threading.Thread(target=update_timer, daemon=True)
                timer_thread.start()
                
                # Cache router classification ƒë·ªÉ tr√°nh g·ªçi AI nhi·ªÅu l·∫ßn
                if "router_cache" not in st.session_state:
                    st.session_state["router_cache"] = {}
                
                # Check cache tr∆∞·ªõc
                if input_query in st.session_state["router_cache"]:
                    router = st.session_state["router_cache"][input_query]
                    response_placeholder.markdown("üîÑ ƒêang s·ª≠ d·ª•ng cache...")
                else:
                    # Ph√¢n lo·∫°i router b√™n trong spinner
                    router = get_router(input_query, model_choice)
                    router = router.strip(" ")
                    # L∆∞u v√†o cache
                    st.session_state["router_cache"][input_query] = router
                
                chat_history = [
                    {"role": msg["role"], "content": msg["content"]}
                    for msg in st.session_state.messages[:-1]
                ]
                if router == "triet-hoc":
                    response_placeholder.markdown("üîç ƒêang t√¨m ki·∫øm th√¥ng tin v·ªÅ Tri·∫øt h·ªçc...")
                    st.caption("This is triet-hoc")
                    if retrieval_choice == "Parent documents retrieval":
                        st.caption("This is parent retrieval")
                        response_placeholder.markdown("üìö ƒêang truy xu·∫•t t√†i li·ªáu...")
                        context = parent_retrieval(input_query, namespace="triet-hoc-children", p_namespace="triet-hoc")

                    elif retrieval_choice == "Hybrid retrieval":
                        st.caption("This is hybrid retrieval")
                        response_placeholder.markdown("üîé ƒêang t√¨m ki·∫øm hybrid...")
                        context = "No context"

                    response_placeholder.markdown("‚úçÔ∏è ƒêang t·∫°o c√¢u tr·∫£ l·ªùi...")
                    response = generate_answer(input_query=input_query, context=context, router=router, chat_history=chat_history, model_choice=model_choice)
                        
                elif router == "lich-su-dang":
                    response_placeholder.markdown("üîç ƒêang t√¨m ki·∫øm th√¥ng tin v·ªÅ L·ªãch s·ª≠ ƒê·∫£ng...")
                    st.caption("This is lich-su-dang")
                    if retrieval_choice == "Parent documents retrieval":
                        st.caption("This is parent retrieval")
                        response_placeholder.markdown("üìö ƒêang truy xu·∫•t t√†i li·ªáu...")
                        context = parent_retrieval(input_query, namespace="lich-su-dang-children", p_namespace="lich-su-dang")

                    elif retrieval_choice == "Hybrid retrieval":
                        st.caption("This is hybrid retrieval")
                        response_placeholder.markdown("üîé ƒêang t√¨m ki·∫øm hybrid...")
                        context = "No context"

                    response_placeholder.markdown("‚úçÔ∏è ƒêang t·∫°o c√¢u tr·∫£ l·ªùi...")
                    response = generate_answer(input_query=input_query, context=context, router=router, chat_history=chat_history, model_choice=model_choice)
                    # response = normal_response(transform_prompt, model_choice, chat_history)
                
                elif router == "normal":
                    response_placeholder.markdown("üí¨ ƒêang chu·∫©n b·ªã tr·∫£ l·ªùi...")
                    st.caption("This is normal")
                    # Tr·∫£ l·ªùi nhanh cho normal chatting kh√¥ng c·∫ßn g·ªçi AI
                    response = random.choice(NORMAL_RESPONSES)
                    # Kh√¥ng c·∫ßn g·ªçi generate_answer cho normal chatting
                    # response = generate_answer(input_query=input_query, context=None, router=router, chat_history=chat_history, model_choice=model_choice)
                
                elif router == "unknown":
                    response_placeholder.markdown("‚ùì ƒêang x·ª≠ l√Ω c√¢u h·ªèi...")
                    st.caption("This is Unknown")
                    response = random.choice(UNKNOWN_RESPONSES)
                    
                else:
                    response_placeholder.markdown("‚ö†Ô∏è ƒêang x·ª≠ l√Ω c√¢u h·ªèi...")
                    response = random.choice(UNLOGIC_RESPONSES)  
                
                # Hi·ªÉn th·ªã response ngay l·∫≠p t·ª©c v·ªõi format ƒë√∫ng
                if isinstance(response, str):
                    # L√†m s·∫°ch response tr∆∞·ªõc khi hi·ªÉn th·ªã
                    clean_resp = clean_response(response)
                    # Hi·ªÉn th·ªã to√†n b·ªô response ngay l·∫≠p t·ª©c ƒë·ªÉ gi·ªØ format
                    response_placeholder.markdown(clean_resp)
                    final_response = clean_resp
                else:
                    # Fallback n·∫øu response kh√¥ng ph·∫£i string
                    final_response = clean_response(str(response))
                    response_placeholder.markdown(final_response)
                
                # L∆∞u response v√†o session state v√† chat history
                st.session_state['messages'].append({"role": "assistant", "content": final_response})
                msgs.add_ai_message(final_response)
                
                # Hi·ªÉn th·ªã th·ªùi gian ph·∫£n h·ªìi cu·ªëi c√πng
                end_time = time.time()
                elapsed_time = end_time - start_time
                timer_placeholder.caption(f"‚è±Ô∏è Th·ªùi gian ph·∫£n h·ªìi: {elapsed_time:.2f} gi√¢y")
def main():
    setup_page()
    model_choice, retrieval_choice, num_retrieval_docs = setup_sidebar()
        
    msgs = setup_chat_interface(model_choice)
    user_input(msgs, model_choice, retrieval_choice)
    
if __name__ == "__main__":
    main()