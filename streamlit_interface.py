import time
import random
import threading
import streamlit as st
from agent import get_router
from langchain_community.chat_message_histories import StreamlitChatMessageHistory
from retriever.parent_retrieval import parent_document_search as parent_retrieval
from agent import generate_answer

# Cache responses cho normal chatting
NORMAL_RESPONSES = [
    "Xin chÃ o! TÃ´i lÃ  trá»£ lÃ½ AI cá»§a báº¡n. TÃ´i cÃ³ thá»ƒ giÃºp báº¡n tráº£ lá»i cÃ¡c cÃ¢u há»i vá» Triáº¿t há»c MÃ¡c-LÃªnin vÃ  Lá»‹ch sá»­ Äáº£ng. Báº¡n cÃ³ cÃ¢u há»i gÃ¬ khÃ´ng?",
    "ChÃ o báº¡n! Ráº¥t vui Ä‘Æ°á»£c trÃ² chuyá»‡n vá»›i báº¡n. TÃ´i cÃ³ thá»ƒ há»— trá»£ báº¡n vá» cÃ¡c váº¥n Ä‘á» há»c thuáº­t liÃªn quan Ä‘áº¿n Triáº¿t há»c vÃ  Lá»‹ch sá»­ Äáº£ng.",
    "Hi! TÃ´i á»Ÿ Ä‘Ã¢y Ä‘á»ƒ giÃºp báº¡n. HÃ£y Ä‘áº·t cÃ¢u há»i vá» Triáº¿t há»c MÃ¡c-LÃªnin hoáº·c Lá»‹ch sá»­ Äáº£ng nhÃ©!",
    "ChÃ o báº¡n! TÃ´i luÃ´n sáºµn sÃ ng há»— trá»£ báº¡n. CÃ³ Ä‘iá»u gÃ¬ tÃ´i cÃ³ thá»ƒ giÃºp vá» Triáº¿t há»c vÃ  Lá»‹ch sá»­ Äáº£ng khÃ´ng?",
    "Xin chÃ o! TÃ´i lÃ  trá»£ lÃ½ chuyÃªn vá» Triáº¿t há»c vÃ  Lá»‹ch sá»­ Äáº£ng. Báº¡n cáº§n tÃ´i giÃºp gÃ¬ hÃ´m nay?",
]

UNKNOWN_RESPONSES = [
    "ÄÃ¢y cÃ³ váº» khÃ´ng pháº£i lÃ  cÃ¢u há»i thuá»™c pháº¡m vi kiáº¿n thá»©c cá»§a tÃ´i. HÃ£y nháº­p cÃ¢u há»i khÃ¡c Ä‘á»ƒ tÃ´i giÃºp báº¡n nhÃ©!",
    "Xin lá»—i, tÃ´i khÃ´ng cÃ³ kiáº¿n thá»©c vá» ná»™i dung báº¡n muá»‘n tÃ¬m. HÃ£y nháº­p cÃ¢u há»i khÃ¡c Ä‘á»ƒ tÃ´i giÃºp báº¡n nhÃ©!",
    "Kiáº¿n thá»©c nÃ y khÃ´ng náº±m trong pháº¡m vi cá»§a tÃ´i. HÃ£y nháº­p cÃ¢u há»i khÃ¡c Ä‘á»ƒ tÃ´i giÃºp báº¡n nhÃ©!",
]

UNLOGIC_RESPONSES = [
    "CÃ¢u há»i cá»§a báº¡n cÃ³ váº¥n Ä‘á» vá» ngá»¯ nghÄ©a. HÃ£y nháº­p cÃ¢u há»i khÃ¡c Ä‘á»ƒ tÃ´i giÃºp báº¡n nhÃ©!",
    "Xin lá»—i, cÃ³ váº» nhÆ° cÃ¢u há»i cá»§a báº¡n Ä‘ang cÃ³ váº¥n Ä‘á». HÃ£y nháº­p cÃ¢u há»i khÃ¡c Ä‘á»ƒ tÃ´i giÃºp báº¡n nhÃ©!",
    "CÃ¢u nÃ y khÃ´ng cÃ³ ngá»¯ nghÄ©a. HÃ£y nháº­p cÃ¢u há»i khÃ¡c Ä‘á»ƒ tÃ´i giÃºp báº¡n nhÃ©!",
]

def reset_conversation():
    """
    Äáº·t láº¡i toÃ n bá»™ tráº¡ng thÃ¡i cá»§a cuá»™c trÃ² chuyá»‡n.
    """
    st.session_state['messages'] = [
        {"role": "assistant", "content": random.choice(
            [
                "Xin chÃ o! TÃ´i lÃ  trá»£ lÃ½ mÃ´n cá»§a báº¡n. TÃ´i sáº½ giÃºp báº¡n tráº£ lá»i cÃ¡c cÃ¢u há»i vá» Triáº¿t há»c vÃ  Lá»‹ch sá»­ Äáº£ng. HÃ£y nháº­p cÃ¢u há»i cá»§a báº¡n vÃ o Ã´ bÃªn dÆ°á»›i Ä‘á»ƒ báº¯t Ä‘áº§u trÃ² chuyá»‡n vá»›i tÃ´i.",
                "ChÃ o báº¡n! Báº¡n cáº§n tÃ´i giÃºp gÃ¬ khÃ´ng? TÃ´i cÃ³ thá»ƒ tráº£ lá»i má»i cÃ¢u há»i cá»§a báº¡n vá» Triáº¿t há»c vÃ  Lá»‹ch sá»­ Äáº£ng.",
                "Báº¡n muá»‘n biáº¿t gÃ¬ vá» Triáº¿t há»c vÃ  Lá»‹ch sá»­ Äáº£ng? HÃ£y nháº­p cÃ¢u há»i cá»§a báº¡n vÃ o Ã´ bÃªn dÆ°á»›i Ä‘á»ƒ báº¯t Ä‘áº§u trÃ² chuyá»‡n vá»›i tÃ´i.",
        ])}
    ] 
    msgs = StreamlitChatMessageHistory(key="langchain_messages")
    msgs.clear()  
    st.rerun()

def response_generator(response):
    """Táº¡o typing effect báº±ng cÃ¡ch hiá»ƒn thá»‹ tá»«ng dÃ²ng"""
    lines = response.split('\n')
    for i, line in enumerate(lines):
        yield '\n'.join(lines[:i+1])
        time.sleep(0.1)

def typing_effect_by_lines(response_placeholder, response_text):
    """Hiá»ƒn thá»‹ response vá»›i typing effect theo tá»«ng dÃ²ng Ä‘á»ƒ giá»¯ format"""
    lines = response_text.split('\n')
    displayed_content = ""
    
    for line in lines:
        if displayed_content:
            displayed_content += '\n' + line
        else:
            displayed_content = line
        response_placeholder.markdown(displayed_content)
        time.sleep(0.1)  # Delay ngáº¯n giá»¯a cÃ¡c dÃ²ng
    
    return displayed_content

def clean_response(response):
    """
    LÃ m sáº¡ch vÃ  format response Ä‘á»ƒ hiá»ƒn thá»‹ Ä‘Ãºng markdown
    """
    if not isinstance(response, str):
        response = str(response)
    
    # Loáº¡i bá» khoáº£ng tráº¯ng thá»«a á»Ÿ Ä‘áº§u vÃ  cuá»‘i
    response = response.strip()
    
    # Thay tháº¿ cÃ¡c escape characters
    response = response.replace('\\n', '\n')
    response = response.replace('\\t', '\t')
    
    # Cáº£i thiá»‡n format cho markdown
    import re
    
    # Äáº£m báº£o cÃ³ khoáº£ng tráº¯ng sau cÃ¡c bullet points
    response = re.sub(r'\n\s*([a-z])\)', r'\n\t\1)', response)
    response = re.sub(r'\n\s*([0-9]+)\.', r'\n\1.', response)
    
    # Äáº£m báº£o cÃ³ xuá»‘ng dÃ²ng sau cÃ¡c heading
    response = re.sub(r'\*\*([^*]+)\*\*\s*:', r'**\1:**\n', response)
    
    # Äáº£m báº£o cÃ³ xuá»‘ng dÃ²ng Ä‘Ãºng cÃ¡ch
    response = re.sub(r'\n\s*\n', '\n\n', response)
    
    return response
    
def setup_page():
    """
    Cáº¥u hÃ¬nh trang web cÆ¡ báº£n
    """
    st.set_page_config(
        page_title="Legal Assistant", 
        page_icon="ğŸ’¬",
        layout="wide" 
    )

def setup_sidebar():
    with st.sidebar:
        st.markdown("""
        <h1 style='text-align: center; color: #4CAF50;'>âš™ï¸ Cáº¥u HÃ¬nh</h1>
        """, unsafe_allow_html=True)
        
        with st.expander("ğŸš€ Chá»n Model AI", expanded=True):
            model_choice = st.selectbox(
                "Chá»n Model Ä‘á»ƒ tráº£ lá»i:",
                ["gemini-2.5-pro", "gemini-2.5-flash"],
                index=0
            )
            st.caption("ğŸ”¹ Model AI sáº½ áº£nh hÆ°á»Ÿng Ä‘áº¿n tá»‘c Ä‘á»™ vÃ  Ä‘á»™ chÃ­nh xÃ¡c cá»§a cÃ¢u tráº£ lá»i.")
          
        with st.expander("ğŸ” TÃ­nh NÄƒng TrÃ­ch Xuáº¥t VÄƒn Báº£n"):
            retrieval_choice = st.selectbox(
                "Chá»n phÆ°Æ¡ng thá»©c truy váº¥n:",
                ["Hybrid retrieval", "Parent documents retrieval"],
                index=0
            )
            st.caption("TÃ­nh nÄƒng nÃ y sáº½ quyáº¿t Ä‘á»‹nh cÃ¡ch dá»¯ liá»‡u Ä‘Æ°á»£c truy xuáº¥t.")
            
            num_retrieval_docs = st.slider(
                "ğŸ”¢ Sá»‘ lÆ°á»£ng vÄƒn báº£n truy xuáº¥t:",
                min_value=1,  
                max_value=10,  
                value=5 
            )
  
            
        with st.expander("ğŸ›  Tuá»³ Chá»n KhÃ¡c"):
            if st.button("ğŸ—‘ XÃ³a cuá»™c trÃ² chuyá»‡n", use_container_width=True):
                reset_conversation()
            st.markdown("""
            <small style='color: grey;'>XÃ³a lá»‹ch sá»­ chat Ä‘á»ƒ báº¯t Ä‘áº§u cuá»™c trÃ² chuyá»‡n má»›i.</small>
            """, unsafe_allow_html=True)
        
    return model_choice, retrieval_choice, num_retrieval_docs
        
def setup_chat_interface(model_choice):
    st.title("Trá»£ LÃ½ Há»c Thuáº­t ğŸ’¬")
    if model_choice == "gemini-2.5-pro" or model_choice == "gemini-2.5-flash":
        st.caption("Trá»£ lÃ½ AI Ä‘Æ°á»£c há»— trá»£ bá»Ÿi Google")

    msgs = StreamlitChatMessageHistory(key="langchain_messages")
    if "messages" not in st.session_state:
        st.session_state['messages'] = [
            {"role": "assistant", "content": random.choice(
                [
                "Xin chÃ o! TÃ´i lÃ  trá»£ lÃ½ mÃ´n cá»§a báº¡n. TÃ´i sáº½ giÃºp báº¡n tráº£ lá»i cÃ¡c cÃ¢u há»i vá» Triáº¿t há»c vÃ  Lá»‹ch sá»­ Äáº£ng. HÃ£y nháº­p cÃ¢u há»i cá»§a báº¡n vÃ o Ã´ bÃªn dÆ°á»›i Ä‘á»ƒ báº¯t Ä‘áº§u trÃ² chuyá»‡n vá»›i tÃ´i.",
                "ChÃ o báº¡n! Báº¡n cáº§n tÃ´i giÃºp gÃ¬ khÃ´ng? TÃ´i cÃ³ thá»ƒ tráº£ lá»i má»i cÃ¢u há»i cá»§a báº¡n vá» Triáº¿t há»c vÃ  Lá»‹ch sá»­ Äáº£ng.",
                "Báº¡n muá»‘n biáº¿t gÃ¬ vá» Triáº¿t há»c vÃ  Lá»‹ch sá»­ Äáº£ng? HÃ£y nháº­p cÃ¢u há»i cá»§a báº¡n vÃ o Ã´ bÃªn dÆ°á»›i Ä‘á»ƒ báº¯t Ä‘áº§u trÃ² chuyá»‡n vá»›i tÃ´i.",
            ])}
        ]
        msgs.add_ai_message(st.session_state.messages[0]["content"])
    
    for msg in st.session_state['messages']:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])
    return msgs

def user_input(msgs, model_choice, retrieval_choice):
    if input_query:= st.chat_input("HÃ£y há»i tÃ´i báº¥t cá»© Ä‘iá»u gÃ¬ vá» Triáº¿t há»c vÃ  Lá»‹ch Sá»­ Äáº£ng!"):
        st.session_state['messages'].append({"role": "user", "content": input_query})
        with st.chat_message("user"):
            st.markdown(input_query)   
        msgs.add_user_message(input_query)
        
        # Hiá»ƒn thá»‹ ngay láº­p tá»©c ráº±ng AI Ä‘ang xá»­ lÃ½
        with st.chat_message("assistant"):
            # Hiá»ƒn thá»‹ spinner ngay láº­p tá»©c
            with st.spinner("Äang suy nghÄ©..."):
                response_placeholder = st.empty()
                timer_placeholder = st.empty()
                start_time = time.time()
                
                # Hiá»ƒn thá»‹ thÃ´ng bÃ¡o ngay láº­p tá»©c
                response_placeholder.markdown("ğŸ¤” Äang phÃ¢n tÃ­ch cÃ¢u há»i...")
                
                # Khá»Ÿi táº¡o timer ngay sau khi báº¯t Ä‘áº§u
                def update_timer():
                    while True:
                        elapsed_time = time.time() - start_time
                        timer_placeholder.caption(f"â±ï¸ Äang xá»­ lÃ½: {elapsed_time:.2f} giÃ¢y")
                        time.sleep(0.1)

                timer_thread = threading.Thread(target=update_timer, daemon=True)
                timer_thread.start()
                
                # Cache router classification Ä‘á»ƒ trÃ¡nh gá»i AI nhiá»u láº§n
                if "router_cache" not in st.session_state:
                    st.session_state["router_cache"] = {}
                
                # Check cache trÆ°á»›c
                if input_query in st.session_state["router_cache"]:
                    router = st.session_state["router_cache"][input_query]
                    response_placeholder.markdown("ğŸ”„ Äang sá»­ dá»¥ng cache...")
                else:
                    # PhÃ¢n loáº¡i router bÃªn trong spinner
                    router = get_router(input_query, model_choice)
                    router = router.strip(" ")
                    # LÆ°u vÃ o cache
                    st.session_state["router_cache"][input_query] = router
                
                chat_history = [
                    {"role": msg["role"], "content": msg["content"]}
                    for msg in st.session_state.messages[:-1]
                ]
                if router == "triet-hoc":
                    response_placeholder.markdown("ğŸ” Äang tÃ¬m kiáº¿m thÃ´ng tin vá» Triáº¿t há»c...")
                    st.caption("This is triet-hoc")
                    if retrieval_choice == "Parent documents retrieval":
                        st.caption("This is parent retrieval")
                        response_placeholder.markdown("ğŸ“š Äang truy xuáº¥t tÃ i liá»‡u...")
                        context = parent_retrieval(input_query, namespace="triet-hoc-children", p_namespace="triet-hoc")

                    elif retrieval_choice == "Hybrid retrieval":
                        st.caption("This is hybrid retrieval")
                        response_placeholder.markdown("ğŸ” Äang tÃ¬m kiáº¿m hybrid...")
                        context = "No context"

                    response_placeholder.markdown("âœï¸ Äang táº¡o cÃ¢u tráº£ lá»i...")
                    response = generate_answer(input_query=input_query, context=context, router=router, chat_history=chat_history, model_choice=model_choice)
                        
                elif router == "lich-su-dang":
                    response_placeholder.markdown("ğŸ” Äang tÃ¬m kiáº¿m thÃ´ng tin vá» Lá»‹ch sá»­ Äáº£ng...")
                    st.caption("This is lich-su-dang")
                    if retrieval_choice == "Parent documents retrieval":
                        st.caption("This is parent retrieval")
                        response_placeholder.markdown("ğŸ“š Äang truy xuáº¥t tÃ i liá»‡u...")
                        context = parent_retrieval(input_query, namespace="lich-su-dang-children", p_namespace="lich-su-dang")

                    elif retrieval_choice == "Hybrid retrieval":
                        st.caption("This is hybrid retrieval")
                        response_placeholder.markdown("ğŸ” Äang tÃ¬m kiáº¿m hybrid...")
                        context = "No context"

                    response_placeholder.markdown("âœï¸ Äang táº¡o cÃ¢u tráº£ lá»i...")
                    response = generate_answer(input_query=input_query, context=context, router=router, chat_history=chat_history, model_choice=model_choice)
                    # response = normal_response(transform_prompt, model_choice, chat_history)
                
                elif router == "normal":
                    response_placeholder.markdown("ğŸ’¬ Äang chuáº©n bá»‹ tráº£ lá»i...")
                    st.caption("This is normal")
                    # Tráº£ lá»i nhanh cho normal chatting khÃ´ng cáº§n gá»i AI
                    response = random.choice(NORMAL_RESPONSES)
                    # KhÃ´ng cáº§n gá»i generate_answer cho normal chatting
                    # response = generate_answer(input_query=input_query, context=None, router=router, chat_history=chat_history, model_choice=model_choice)
                
                elif router == "unknown":
                    response_placeholder.markdown("â“ Äang xá»­ lÃ½ cÃ¢u há»i...")
                    st.caption("This is Unknown")
                    response = random.choice(UNKNOWN_RESPONSES)
                    
                else:
                    response_placeholder.markdown("âš ï¸ Äang xá»­ lÃ½ cÃ¢u há»i...")
                    response = random.choice(UNLOGIC_RESPONSES)  
                
                # Hiá»ƒn thá»‹ response ngay láº­p tá»©c vá»›i format Ä‘Ãºng
                if isinstance(response, str):
                    # LÃ m sáº¡ch response trÆ°á»›c khi hiá»ƒn thá»‹
                    clean_resp = clean_response(response)
                    
                    # TÃ¹y chá»n: cÃ³ thá»ƒ báº­t typing effect theo dÃ²ng hoáº·c hiá»ƒn thá»‹ ngay
                    # Äá»ƒ báº­t typing effect, uncomment dÃ²ng dÆ°á»›i vÃ  comment dÃ²ng response_placeholder.markdown
                    # final_response = typing_effect_by_lines(response_placeholder, clean_resp)
                    
                    # Hiá»ƒn thá»‹ toÃ n bá»™ response ngay láº­p tá»©c Ä‘á»ƒ giá»¯ format
                    response_placeholder.markdown(clean_resp)
                    final_response = clean_resp
                else:
                    # Fallback náº¿u response khÃ´ng pháº£i string
                    final_response = clean_response(str(response))
                    response_placeholder.markdown(final_response)
                
                # LÆ°u response vÃ o session state vÃ  chat history
                st.session_state['messages'].append({"role": "assistant", "content": final_response})
                msgs.add_ai_message(final_response)
                
                # Hiá»ƒn thá»‹ thá»i gian pháº£n há»“i cuá»‘i cÃ¹ng
                end_time = time.time()
                elapsed_time = end_time - start_time
                timer_placeholder.caption(f"â±ï¸ Thá»i gian pháº£n há»“i: {elapsed_time:.2f} giÃ¢y")
def main():
    setup_page()
    model_choice, retrieval_choice, num_retrieval_docs = setup_sidebar()
        
    msgs = setup_chat_interface(model_choice)
    user_input(msgs, model_choice, retrieval_choice)
    
if __name__ == "__main__":
    main()